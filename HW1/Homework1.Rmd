---
title: "Code for Homework 1"
author: "Hyungkyu Lim"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE ,tidy.opts=list(width.cutoff = 60), tidy = TRUE)
library(lattice)
library(class)
library(knitr)
```

##Question 1

(10 points) Consider the Student Performance Data Set on the UCI machine
learning repository (https://archive.ics.uci.edu/ml/datasets/student+performance).
Suppose that you are getting this data in order to build a predictive model for First
Period Grades. Using the full dataset, investigate the data using exploratory data
analysis such as scatterplots, and other tools we have discussed in class. Preprocess
this data and justify your choices (elimination of outliers, elimination of
variables, variable transformations, etc.) in your write up. Submit the cleaned
dataset as an *.RData file. 

```{r}
d1=read.table("~/Desktop/student/student-mat.csv",sep=";",header=TRUE)
d2=read.table("~/Desktop/student/student-por.csv",sep=";",header=TRUE)

d3=merge(d1,d2,by=c("school","sex","age","address","famsize","Pstatus",
                    "Medu","Fedu","Mjob","Fjob","reason","nursery","internet"))


```

```{r}

d3$guardian.y <- NULL
d3$traveltime.y<-NULL
d3$studytime.y<- NULL
d3$schoolsup.y <- NULL
d3$famsup.y<-NULL
d3$activities.y<-NULL
d3$higher.y<- NULL
d3$romantic.y <-NULL
d3$famrel.y <-NULL
d3$freetime.y<-NULL
d3$goout.y <- NULL
d3$Dalc.y <- NULL
d3$Walc.y <-NULL
d3$health.y <-NULL
d3$G2.x <- NULL
d3$G3.x <- NULL
d3$G2.y <-NULL
d3$G3.y <-NULL

colnames(d3)[14] <- "guardian"
colnames(d3)[15] <- "traveltime"
colnames(d3)[16] <- "studytime"
colnames(d3)[18] <- "schoolsup"
colnames(d3)[19] <- "famsup"
colnames(d3)[21] <- "activities"
colnames(d3)[22] <- "higher"
colnames(d3)[23] <- "romantic"
colnames(d3)[24] <- "famrel"
colnames(d3)[25] <- "freetime"
colnames(d3)[26] <- "goout"
colnames(d3)[27] <- "Dalc"
colnames(d3)[28] <- "Walc"
colnames(d3)[29] <- "health"


d3$TotalG1 <- (d3$G1.x + d3$G1.y)


save(d3, file="Clean.RData")

```

```{r}
par(mfrow=c(1,3))
hist(d3$G1.x,breaks= 0 + (0:4)*5, col="grey", 
     main= "First Period Grade for Math", xlab= "Grade")
hist(d3$G1.y, breaks= 0 + (0:4)*5, col="grey", 
     main = "First Period Grade for Portuguese", xlab= "grade")
hist(d3$TotalG1,breaks = 0 + (0:8)*5, col="grey", 
     main = "Combined Grade", xlab="grade")
```

```{r}
par(mfrow=c(2,3))
plot(G1.x~., data=d3)


```


```{r}
par(mfrow=c(2,3))
plot(d3$G1.y~., data=d3)

```

```{r}
par(mfrow=c(2,3))
plot(d3$TotalG1~., data=d3)

```

##Question2

(10 points) Perform a multiple regression on the dataset you pre-processed in
question one. The response are the first period grades. Use the lm() function in
R.

a) Which predictors appear to have a significant relationship to the response.
b) What suggestions would you make to a first-year student trying to achieve
good grades.

```{r}
lm.fit = lm(TotalG1~school+ sex + age + address + famsize+ Pstatus +
              Medu + Fedu + Mjob + Fjob + reason + nursery +
              internet + guardian + traveltime + studytime + schoolsup + famsup +                    activities + higher + romantic + famrel + freetime + goout +
              Dalc + Walc + health, data=d3 )

summary(lm.fit)
```


```{r}
lm.fit1 = lm(G1.x~school+ sex + age + address + famsize+ Pstatus + 
              Medu + Fedu + Mjob + Fjob + reason + nursery + internet + guardian +                    traveltime + studytime + schoolsup + famsup + 
               activities + higher + romantic + famrel + freetime + goout + 
               Dalc + Walc + health + failures.x + paid.x + absences.x, data=d3 )

summary(lm.fit1)
```

```{R}

lm.fit2 = lm(G1.y~school+ sex + age + address + famsize+ 
             Pstatus + Medu + Fedu + Mjob + Fjob + reason + nursery +
               internet + guardian + traveltime + studytime + schoolsup + 
               famsup + activities + higher + romantic + famrel + freetime + 
               goout + Dalc + Walc + health + failures.y + paid.y + absences.y, 
               data=d3 )

summary(lm.fit2)

```




c) Use the * and : symbols to fit models with interactions. Are there any
interactions that are significant? 

```{r}

total_grade_model1<- lm(TotalG1~schoolsup*studytime,data=d3)
summary(total_grade_model1)
par(mfrow=c(2,2))
plot(total_grade_model1)

math_grade_model1<- lm(G1.x~failures.x*higher,data=d3)
summary(math_grade_model1)
par(mfrow=c(2,2))
plot(math_grade_model1)


portuguese_grade_model1 <- lm(G1.y~failures.y*higher,data=d3)
summary(portuguese_grade_model1)
par(mfrow=c(2,2))
plot(portuguese_grade_model1)


```



##Question3

(10 points) ISL textbook exercise 2.10 modified: This exercise concerns the
boston housing data in the MASS library (>library(MASS) >data(Boston)).

a) Make pairwise scatterplots of the predictors, and describe your findings. 

  
```{r}
library(MASS)

pairs(Boston)


```


b) Are any of the predictors associated with per capita crime rate?

```{r}
cor(Boston$rad,Boston$crim)
cor(Boston$tax, Boston$crim)
cor(Boston$lstat, Boston$crim)
cor(Boston$dis, Boston$crim)
cor(Boston$medv, Boston$crim)


par(mfrow=c(2,3))
plot(Boston$rad,Boston$crim)
plot(Boston$tax, Boston$crim)
plot(Boston$lstat, Boston$crim)
plot(Boston$dis, Boston$crim)
plot(Boston$medv, Boston$crim)


     
```

c) Do any of the suburbs of Boston appear to have particularly high crime rates?
Tax rates? Pupil-teacher ratios? Comment on the range of each predictor.

```{r}
par(mfrow=c(1,3))

boxplot(Boston$crim, breaks=10)

boxplot(Boston$tax, breaks=10)

boxplot(Boston$ptratio, breaks=10)

```

d) In this data set, how many of the suburbs average more than seven rooms per
dwelling? More than eight rooms per dwelling? Comment on the suburbs
that average more than eight rooms per dwelling.

```{r}
hist(Boston$rm, breaks=25, main="average number of rooms per dwelling")

nrow(Boston[Boston$rm>7,])

nrow(Boston[Boston$rm>8,])

eight <- Boston[Boston$rm>8,]


hist(eight$crim, breaks=5)


mean(Boston$crim)
mean(eight$crim)



mean(Boston$medv)
mean(eight$medv)


mean(Boston$ptratio)
mean(eight$ptratio)


mean(Boston$chas)
mean(eight$chas)



mean(Boston$rad)
mean(eight$rad)


```

##Question4

(10 points) ESL textbook exercise 2.8 modified: Compare the classification
performance of linear regression and k-nearest neighbor classification on the
zipcode data. In particular, consider only the 2’s and 3’s for this problem, and k =
1,3,5,7,9,11, 13,15. Show both the training and the test error for each choice of k.
The zipcode data is available in the ElemStatLearn package. 

```{r}
library(ElemStatLearn)

zip_train <- zip.train

zip_test <- zip.test

data_zip_train <- data.frame(zip_train)

data_zip_test <- data.frame(zip_test)

filtered_train <- subset(data_zip_train, data_zip_train$X1==2 | data_zip_train$X1==3)

filtered_test <- subset(data_zip_test, data_zip_test$X1==2 | data_zip_test$X1==3)

model_linear <- lm(X1~.-X1, data=filtered_train)

predicted_test<- round(predict(model_linear, newdata=filtered_test[,-1]))

real <- filtered_test[,1]

mse <- mean((as.numeric(predicted_test)-real)^2)

mse



knn1_train <- knn(filtered_train[,-1],filtered_train[,-1],filtered_train[,1], 1)
knn3_train <- knn(filtered_train[,-1],filtered_train[,-1],filtered_train[,1], 3)
knn5_train <- knn(filtered_train[,-1],filtered_train[,-1],filtered_train[,1], 5)
knn7_train <- knn(filtered_train[,-1],filtered_train[,-1],filtered_train[,1], 7)
knn9_train <- knn(filtered_train[,-1],filtered_train[,-1],filtered_train[,1], 9)
knn11_train <- knn(filtered_train[,-1],filtered_train[,-1],filtered_train[,1], 11)
knn13_train <- knn(filtered_train[,-1],filtered_train[,-1],filtered_train[,1], 13)
knn15_train <- knn(filtered_train[,-1],filtered_train[,-1],filtered_train[,1], 15)


meanofError_knn1_train<-mean((filtered_train[,1]-as.numeric(knn1_train))^2)
meanofError_knn3_train<-mean((filtered_train[,1]-as.numeric(knn3_train))^2)
meanofError_knn5_train<-mean((filtered_train[,1]-as.numeric(knn5_train))^2)
meanofError_knn7_train<-mean((filtered_train[,1]-as.numeric(knn7_train))^2)
meanofError_knn9_train<-mean((filtered_train[,1]-as.numeric(knn9_train))^2)
meanofError_knn11_train<-mean((filtered_train[,1]-as.numeric(knn11_train))^2)
meanofError_knn13_train<-mean((filtered_train[,1]-as.numeric(knn13_train))^2)
meanofError_knn15_train<-mean((filtered_train[,1]-as.numeric(knn15_train))^2)

abc <- data.frame(meanofError_knn1_train,meanofError_knn3_train,
                  meanofError_knn5_train,meanofError_knn7_train,
                  meanofError_knn9_train,
                  meanofError_knn11_train,meanofError_knn13_train,
                  meanofError_knn15_train)

data_mse_train <- c(meanofError_knn1_train,meanofError_knn3_train,
                    meanofError_knn5_train,meanofError_knn7_train,
                    meanofError_knn9_train,meanofError_knn11_train,
                    meanofError_knn13_train,meanofError_knn15_train)



knn1 <- knn(filtered_train[,-1],filtered_test[,-1],filtered_train[,1], 1)
knn3 <- knn(filtered_train[,-1],filtered_test[,-1],filtered_train[,1], 3)
knn5 <- knn(filtered_train[,-1],filtered_test[,-1],filtered_train[,1], 5)
knn7 <- knn(filtered_train[,-1],filtered_test[,-1],filtered_train[,1], 7)
knn9 <- knn(filtered_train[,-1],filtered_test[,-1],filtered_train[,1], 9)
knn11<- knn(filtered_train[,-1],filtered_test[,-1],filtered_train[,1], 11)
knn13 <- knn(filtered_train[,-1],filtered_test[,-1],filtered_train[,1], 13)
knn15 <- knn(filtered_train[,-1],filtered_test[,-1],filtered_train[,1], 15)


meanofError_knn1<-mean((filtered_test[,1]-as.numeric(knn1))^2)
meanofError_knn3<-mean((filtered_test[,1]-as.numeric(knn3))^2)
meanofError_knn5<-mean((filtered_test[,1]-as.numeric(knn5))^2)
meanofError_knn7<-mean((filtered_test[,1]-as.numeric(knn7))^2)
meanofError_knn9<-mean((filtered_test[,1]-as.numeric(knn9))^2)
meanofError_knn11<-mean((filtered_test[,1]-as.numeric(knn11))^2)
meanofError_knn13<-mean((filtered_test[,1]-as.numeric(knn13))^2)
meanofError_knn15<-mean((filtered_test[,1]-as.numeric(knn15))^2)



data_mse <- c(meanofError_knn1,meanofError_knn3,meanofError_knn5,meanofError_knn7,
              meanofError_knn9,meanofError_knn11,meanofError_knn13,meanofError_knn15)


par(mfrow=c(1,2))


plot(data_mse_train, col="blue",main="MSE for train_data")

plot(data_mse,col="red", main="MSE for test_data")





```



quality1box <- ggplot(quality0, aes( x= factor(quality),y = priceavg/1000)) +
      geom_boxplot() +
      scale_y_log10()
quality1box



